<!--Copyright Â© ZOMI é€‚ç”¨äº[License](https://github.com/Infrasys-AI/AIInfra)ç‰ˆæƒè®¸å¯-->

# MoE ä»åŸç†åˆ°åˆ†å¸ƒå¼å®ç°ï¼ˆDoneï¼‰

> Author by: å¼ å¤©ç¿”ã€ZOMI

åœ¨å‰é¢çš„å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»å®ç°äº†ä¸€ä¸ªå•æœºå•å¡MoEçš„å°demoï¼Œä½†æ˜¯å®é™…åœºæ™¯ä¸‹MoEæ¨¡å‹å¤ªå¤§ï¼ˆä¸“å®¶å¤§å°ï¼Œä¸“å®¶æ•°é‡ï¼‰ï¼Œå•GPUå†…å­˜ä¸èƒ½å®¹çº³æ‰€æœ‰ä¸“å®¶ï¼Œå› æ­¤è¦é‡‡å–åˆ†å¸ƒå¼éƒ¨ç½²çš„ç­–ç•¥æ‰èƒ½è®©ä¸“å®¶æƒé‡å­˜å‚¨åœ¨GPUæ˜‚è´µçš„å†…å­˜ä¸­ã€‚é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œå·²çŸ¥æœ‰DPã€TPã€EPç­‰å¤šç§å¹¶è¡Œæ–¹æ¡ˆï¼Œå“ªä¸€ç§æ–¹æ¡ˆæ›´åŠ è´´åˆMoEæ¨¡å‹ï¼ˆç®—æ³•ä¾§ï¼‰å‘¢ï¼Ÿä¸ºä»€ä¹ˆå‘¢ï¼Ÿè¿™äº›å¹¶è¡Œæ–¹æ¡ˆä¹‹é—´å­°ä¼˜å­°åŠ£ï¼Œå„è‡ªé€‚åˆä»€ä¹ˆåœºæ™¯å‘¢ï¼Ÿæœ¬æ–‡å°±è®©æˆ‘ä»¬ä¸€èµ·æ¥æ¢ç©¶åŸç†ï¼Œæœ€ååŠ¨æ‰‹å®ç°ä¸€ä¸ªåˆ†å¸ƒå¼MoEï¼ˆEPï¼‰çš„åˆ†å¸ƒå¼demoã€‚

# åŸç†åˆ†æ

## DPã€TPã€EPå®šä¹‰
é¦–å…ˆå›ç­”â€œæ˜¯ä»€ä¹ˆâ€ï¼Œå‚è€ƒäº†[è¿™ç¯‡æ–‡ç« ](https://zhuanlan.zhihu.com/p/1967192540953425479)ï¼š
* DPï¼šæ¯å—GPUå¤åˆ¶å…¨é‡æ¨¡å‹ï¼Œæ‹†åˆ†è¾“å…¥batchç»™æ¯ä¸ªè®¾å¤‡ç‹¬ç«‹è®¡ç®—ï¼Œæ¯ä¸ªè®¾å¤‡éƒ½èƒ½ç‹¬ç«‹å¾—åˆ°ç»“æœï¼Œä¸éœ€è¦é€šä¿¡ã€‚
* TPï¼šå°†æ¨¡å‹æƒé‡åˆ‡åˆ†æˆè‹¥å¹²chunksï¼Œå°†å°chunkæ”¾åœ¨å•ä¸ªGPUä¸Šã€‚ç”±äºæ¨¡å‹è¢«åˆ‡åˆ†ï¼Œä¸èƒ½ç‹¬ç«‹å¾—åˆ°ç»“æœï¼Œæ‰€ä»¥éœ€è¦AllReduceé€šä¿¡ã€‚å‚è€ƒè¿™ç¯‡[æ–‡ç« ](https://zhuanlan.zhihu.com/p/622212228)ï¼Œå¾ˆæ¨èé˜…è¯»ã€‚
    * æ¨¡å‹åˆ‡åˆ†æœ‰ä¸¤ç§æ–¹å¼ï¼šæ¨ªç€åˆ‡å’Œç«–ç€åˆ‡ï¼›è¿™é‡Œæœ€å¥½ææ˜ç™½â€”â€”MLPå…ˆåˆ—åˆ‡å†è¡Œåˆ‡ï¼Œç”±äºGELUçš„æ€§è´¨å¯ä»¥å‡å°‘ä¸€æ¬¡ä¸å¿…è¦çš„allreduceé€šä¿¡![](./images/Practice03DistMoE01.png)
    * Transformeræ¶æ„ä¸­å¤§æ¦‚æœ‰ä¸¤å—å¯ä»¥ç”¨TPåšåˆ‡åˆ†ï¼šMLPå’ŒMHAï¼ŒMLPåˆ‡åˆ†å°±åœ¨ä¸Šå›¾ï¼ŒMLAåˆ‡åˆ†å°±æ²¿ç€num_headsç»´åº¦åˆ‡åˆ†QKVweightsåˆ°å¤šä¸ªGPUsä¸Šã€‚
* EPï¼šé’ˆå¯¹MoEè¿™ä¸€å±‚ï¼Œå°†ä¸“å®¶æƒé‡ï¼ˆMLPï¼‰ç‹¬ç«‹çš„æ”¾åœ¨ä¸åŒçš„GPUä¸Šã€‚æ¯”å¦‚æœ‰32ä¸ªä¸“å®¶å’Œ4å—GPUï¼Œåˆ™æ¯ä¸ªGPUå®¹çº³8ä¸ªç‹¬ç«‹çš„ä¸“å®¶æƒé‡ã€‚

## EP AlltoAll 

EPéƒ¨ç½²å¸¦æ¥çš„ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜æ˜¯ï¼Œä¸“å®¶ä¸å†åœ¨åŒä¸€ä¸ªGPUä¸Šäº†ï¼Œè€Œè¾“å…¥batch-sizeä¸ªtokensï¼Œå®ƒä»¬æ ¹æ®gateç½‘ç»œæ‰“åˆ†ï¼Œé€‰æ‹©è¯¥tokenè¦å‰å¾€çš„ä¸“å®¶ï¼›åœ¨é€‰ä¸­ä¸“å®¶ä¸Šè®¡ç®—å®Œä¹‹åéœ€è¦é‡æ–°å›åˆ°å®ƒæ¥çš„é‚£å¼ å¡ä¸Šï¼Œè¿™ä¸ªè¿‡ç¨‹å°±ç§°ä¸ºAlltoAllï¼ˆç®€ç§°ataï¼‰é€šä¿¡ã€‚

é…åˆå›¾ç‰‡ç›´è§‚çš„ç†è§£ä¸€ä¸‹ï¼Œå›¾ç‰‡æ¥æºï¼šhttps://zhuanlan.zhihu.com/p/28867733102

![dispatch_visualiaze](./images/Practice03DistMoE02.png)

æœ‰å››ä¸ªdeviceï¼Œæ¯ä¸ªGPUè¾“å…¥ä¸¤ä¸ªtokenï¼Œæ¯ä¸ªtokené€‰æ‹©å››ä¸ªä¸“å®¶ï¼ˆå››ä¸ªç®­å¤´ï¼‰ã€‚é¢œè‰²ä»£è¡¨ä¸“å®¶ï¼Œæœ‰å…«ç§é¢œè‰²æ„å‘³ç€æœ‰å…«ä¸ªä¸“å®¶ï¼Œæ¯å—GPUä¸Šæœ‰ä¸¤ä¸ªä¸“å®¶ï¼ˆæƒé‡ï¼‰ã€‚tokenæœ€å¼€å§‹æ˜¯æ²¡æœ‰é¢œè‰²çš„ï¼ˆç°è‰²ï¼Œä»£è¡¨è¿˜æ²¡é€‰æ‹©ä¸“å®¶ï¼‰ã€‚

æ‹¿device1ä¸Šçš„token2ä¸¾ä¾‹ï¼Œæœ‰å››ä¸ªç®­å¤´ä»£è¡¨é€‰ä¸­äº†å››ä¸ªä¸“å®¶ã€‚permuteè¿™æ­¥ä¹‹åä»£è¡¨åšå®Œäº†ä¸“å®¶é€‰æ‹©ï¼ˆtokenå¼€å§‹æœ‰é¢œè‰²ï¼Œé¢œè‰²ä»£è¡¨äº†è¦å»çš„GPUâ€œç»„â€ï¼Œè¿™é‡Œä¸€ä¸ªGPUä¸Šæœ‰ä¸¤ç§é¢œè‰²ï¼Œä¹Ÿå°±æ˜¯ä¸¤â€œç»„â€ï¼‰ã€‚alltoallè¿™æ­¥ä¹‹åï¼Œæ¯ä¸ªtokenå»åˆ°é¢œè‰²å¯¹åº”çš„ä¸“å®¶ã€‚æœ€åsort_chunksby_idxsï¼ŒåŒä¸€å—GPUå†…æœ‰ä¸¤ç§é¢œè‰²ï¼Œæ¯ä¸ªé¢œè‰²å†…æ ¹æ®è¾“å…¥tokenidå¤§å°åšå‡åºã€‚

ataåœ¨NCCLæ–‡æ¡£ä¸­æ˜¯è¿™ä¹ˆå®šä¹‰çš„ï¼šæ¯ä¸ªè¿›ç¨‹å‘æ‰€æœ‰å…¶ä»–è¿›ç¨‹å‘é€countä¸ªå€¼ï¼Œå¹¶ä»æ‰€æœ‰å…¶ä»–è¿›ç¨‹æ¥æ”¶countä¸ªå€¼ã€‚å‘é€åˆ°ç›®æ ‡è¿›ç¨‹jçš„æ•°æ®å–è‡ªsendbuff+j\*countï¼Œä»æºè¿›ç¨‹iæ¥æ”¶çš„æ•°æ®è¢«æ”¾ç½®åœ¨recvbuff+i\*countå¤„ã€‚å¯¹åº”ç€ä¸‹é¢è¿™å¼ å›¾ï¼š


![NCCL_AlltoAll](./images/Practice03DistMoE03.png)


è€Œå®ƒåœ¨Pytorchä¸­æœ‰è¿™æ ·ä¸€ä¸ªæ¥å£ï¼Œå‡½æ•°ç­¾åï¼š`torch.distributed.all_to_all_single(output, input, output_split_sizes=None, input_split_sizes=None, group=None, async_op=False)`
å°†è¾“å…¥å¼ é‡æ‹†åˆ†ï¼Œç„¶åå°†æ‹†åˆ†åçš„åˆ—è¡¨åˆ†æ•£åˆ°ç»„ä¸­çš„æ‰€æœ‰è¿›ç¨‹ã€‚ä¹‹åï¼Œä»ç»„ä¸­æ‰€æœ‰è¿›ç¨‹æ¥æ”¶çš„å¼ é‡ä¼šè¢«è¿æ¥èµ·æ¥ï¼Œå¹¶ä½œä¸ºå•ä¸ªè¾“å‡ºå¼ é‡è¿”å›ã€‚

## ä¸ºä»€ä¹ˆå¤§è§„æ¨¡éƒ¨ç½²ä¼˜å…ˆé€‰æ‹©EPï¼Ÿ

å®Œå…¨ï¼ˆMoE+non-MoEï¼‰ç”¨DPéƒ¨ç½²ç”±äºå†…å­˜åŸå› é¦–å…ˆè¢«æ’é™¤ï¼Œæˆ‘ä»¬è¯•ç€ä»è®¡ç®—ã€é€šä¿¡ä¸¤ä¸ªè§’åº¦å»åˆ†æTPã€EPå­°ä¼˜å­°åŠ£ï¼Ÿ

### é€šä¿¡é‡åˆ†æ

ç»™å‡ºæŠ½è±¡çš„å®šé‡åˆ†æï¼šmoe_config:{num_experts, ep_world_size(rank_size), topk}, local_token.shape = [b, s, h]

åˆå§‹ï¼Œæ¯ä¸ªrankæœ‰$b*s$ä¸ªtokenï¼›dispatchå®Œæˆä¹‹åï¼Œæ¯ä¸ªrankæœ‰$b*s*topk$ä¸ªtokenï¼ˆå‡è®¾ä¸“å®¶è´Ÿè½½å‡è¡¡ï¼‰ã€‚æˆ‘ä»¬ç°åœ¨æƒ³æ±‚å‡ºéœ€è¦çœŸæ­£å‘é€å‡ºå»çš„tokenæ•°é‡ï¼ˆç»ˆç‚¹dstä¸åœ¨æœ¬rankä¸Šï¼‰ï¼Œæ¯ä¸ªrankå‘é€$b*s*topk$ä¸ªtokenï¼Œè¿™ä¸ªtokenè½åœ¨å…¶ä»–rankçš„æ¦‚ç‡æ˜¯$\frac{ep\_world\_size-1}{ep\_world\_size}$ï¼Œæ‰€ä»¥å¯¹æœ¬rankçœŸæ­£éœ€è¦è·¨å¡å‘é€å‡ºå»çš„tokenæ•°é‡çš„æœŸæœ›æ˜¯$b*s*topk* \frac{ep\_world\_size-1}{ep\_world\_size}$ã€‚åŠç²¾åº¦æƒ…å†µä¸‹ï¼Œæ•°æ®é‡æ˜¯$2*b*s*topk* \frac{ep\_world\_size-1}{ep\_world\_size}*h$ bytesã€‚åŒæ—¶ï¼Œcombineæ˜¯dispatchçš„é€†è¿‡ç¨‹ï¼Œå› æ­¤å¯¹äºæ¯ä¸ªrankæ¥è¯´ï¼ŒåŠç²¾åº¦ï¼Œå®Œæ•´ep ataé€šä¿¡é‡è¿‘ä¼¼ä¸º$4*b*s*h*topk$ Bytesã€‚

è€ŒTPï¼Œåœ¨ä¸Šé¢çš„å›¾é‡Œï¼ŒZ1Z2éƒ½æ˜¯$V = [b,s,h]$ï¼Œéœ€è¦åšä¸€æ¬¡allreduceå¾—åˆ°æœ€åçš„Zï¼ŒåŒæ ·å¯¹äºåŠç²¾åº¦ï¼Œæ¯ä¸ªtp-ranké€šä¿¡çš„æ•°æ®é‡æ˜¯$2*b*s*h*2 = 4*b*s*h$ bytesã€‚ç¬¬ä¸€ä¸ª2å› ä¸ºåŠç²¾åº¦ï¼Œç¬¬äºŒä¸ª2å› ä¸ºring-allreduceåŒ…å«äº†reduce scatterå’Œallgatherä¸¤ä¸ªæ­¥éª¤ã€‚å‡è®¾TPsize=Tï¼Œæ¯ä¸ªrankéœ€è¦è¿›è¡Œé€šä¿¡çš„tensorå¤§å°æ˜¯Vï¼Œring-allreduceä¼šå°†Våˆ‡æˆ$\frac{V}{T}$å¤§å°çš„chunkã€‚åœ¨reduce scatteré˜¶æ®µï¼Œæ¯ä¸ªstepä¸‹æ¯ä¸ªrankå‘é€$\frac{V}{T}$çš„chunkï¼Œæ€»å…±æœ‰$T-1$æ­¥ï¼Œå› æ­¤åœ¨reduce scatteré˜¶æ®µï¼Œæ¯ä¸ªrankå‘é€äº†$\frac{T-1}{T}V$æ•°æ®ã€‚allgatheré˜¶æ®µåŒç†ï¼Œå› æ­¤å¯¹äºæ¯ä¸ªtp rankï¼Œring-allreduceé€šä¿¡é‡æ˜¯$2 \times \frac{T-1}{T}V$ï¼Œåœ¨åŠç²¾åº¦æƒ…å†µä¸‹ï¼Œçº¦ç­‰äº$4*b*s*h*$ bytesã€‚

ï¼ˆä¸Šé¢çš„åˆ†æä¸­ï¼ŒTPå’ŒEPéƒ½è¿‘ä¼¼æ‰äº†$\frac{T-1}{T}$è¿™ä¸ªç³»æ•°ï¼Œæ‰€ä»¥å¾—åˆ°çš„ç»“è®ºæ˜¯ç²¾ç¡®çš„ï¼‰çœ‹èµ·æ¥TPæ¯”EPä¼˜åŒ–äº†topkå€çš„é€šä¿¡é‡ï¼ŒçœŸçš„æ˜¯è¿™æ ·å—ï¼Ÿ

å®é™…éƒ¨ç½²ä¸‹ï¼Œè¿˜éœ€è¦è€ƒè™‘DPçš„å› ç´ ã€‚å‡è®¾æ€»tokenæ•°é‡æ˜¯$1*128$ï¼Œworld_size=32ï¼ˆgpuæ•°é‡ï¼Œ4å¼ 8å¡çš„æœºå™¨ï¼‰ã€‚
* å¯¹äºTP=8æ¥è¯´ï¼ŒDP=4ï¼Œé¦–å…ˆå››å°æœºå™¨ï¼Œæ¯ä¸ªæœºå™¨è¾“å…¥$128 \div 4 =32$ä¸ªtokenï¼Œå¯¹äºæ¯ä¸ªtprankæ¥è¯´ï¼Œé€šä¿¡é‡æ˜¯$4*1*32*h=128h$bytesã€‚
* ä½†æ˜¯å¯¹äºEP=8æ¥è¯´ï¼Œå¼€EPå¹¶ä¸å½±å“DPæ•°é‡ã€‚åªæœ‰moeå±‚é€šè¿‡è·¨æœºEP ataè¿›è¡Œé€šä¿¡ï¼Œè€Œémoeå±‚å¯ä»¥å¼€DP=32ï¼Œæƒé‡å®Œå…¨å¤åˆ¶ï¼Œå†…å­˜å‹åŠ›ç¨å¤§ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯å¼ å¡è¾“å…¥$128 \div 32 =4$ä¸ªtokenï¼Œåœ¨gatingè®¡ç®—å®Œä¹‹åï¼Œtokené€šè¿‡ataè¿›è¡Œä¸€æ¬¡æœºå†…é€šä¿¡ï¼ˆå› ä¸ºEP=8ï¼Œè€Œä¸€ä¸ªèŠ‚ç‚¹å…«å¼ å¡ï¼Œæ­£å¥½ä¸éœ€è¦è·¨æœºé€šä¿¡ï¼‰ï¼Œåœ¨dstå¡è®¡ç®—å®Œåè¿”å›åˆ°srcå¡ã€‚é€šä¿¡é‡æ˜¯$4*1*4*h*topk=16h*topk$ bytesã€‚
* æ­¤æ—¶å†å¯¹æ¯”TPã€EPé€šä¿¡é‡ï¼Œå½“$topk>8$æ—¶ï¼ŒEPé€šä¿¡é‡å¤§äºTPï¼Œå¦åˆ™EPæ›´ä¼˜ã€‚äº‹å®ä¸Šï¼ŒæŠ½è±¡ä¸€ä¸‹å°±å¯ä»¥çŸ¥é“ï¼Œè¿™é‡Œçš„8æ­£æ˜¯parallelsize=tpsize=epsizeã€‚
* å¾—å‡ºç»“è®ºï¼Œå½“$top\_k<parallel\_size$æ—¶ï¼ŒEPæ›´ä¼˜ã€‚

### è®¡ç®—ä¼˜åŠ¿åˆ†æ
è®¡ç®—ä¸Šçš„ä¼˜åŠ¿ä¸»è¦æ¥æºäºEPå¯ä»¥åœ¨æœºå†…å°†å¤šä¸ªæœ¬åœ°ä¸“å®¶è®¡ç®—èšåˆä¸ºå•ä¸ªæ‰¹å¤„ç†GEMM(batched-gemm, bmm)æ“ä½œã€‚è¿™æ ·æˆ‘ä»¬å°±ä¸ç”¨é€šè¿‡`for expert in range(num_experts):`è¿™æ ·çš„å¾ªç¯ï¼Œé™ä½äº†é¢‘ç¹kernel launchçš„å¼€é”€ï¼›é™¤æ­¤ä»¥å¤–ï¼Œç”±äºGPUé’ˆå¯¹å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå°†å¤šä¸ªå°å°ºå¯¸çŸ©é˜µä¹˜æ³•èšåˆæˆå•ä¸ªå¤§å°ºå¯¸çŸ©é˜µä¹˜æ³•çš„æ“ä½œèƒ½æ›´å¥½åœ°å‘æŒ¥å…¶æ€§èƒ½ï¼Œä»è€Œæé«˜åˆ©ç”¨ç‡å’Œæ•ˆç‡ã€‚

å…·ä½“å¯ä»¥å»çœ‹æˆ‘ç¿»è¯‘çš„è¿™ç¯‡åšå®¢ï¼š[What Shapes Do Matrix Multiplications Like?](https://zhuanlan.zhihu.com/p/1984323735117919137)ï¼Œä»¥åŠ Pytorch Blog â€”â€” [Training MoEs at Scale with PyTorch](https://pytorch.org/blog/training-moes/)

# ä»£ç å®ç°

è¿™ä¸€èŠ‚æŠŠå‰é¢çš„åˆ†æè½åˆ°ä»£ç ï¼šæˆ‘ä»¬å®ç°ä¸€ä¸ª **Expert-Parallelï¼ˆEPï¼‰MoE layer** çš„æœ€å°å¯è¿è¡Œç‰ˆæœ¬ï¼Œå¹¶ç”¨ä¸€ä¸ª toy ä»»åŠ¡è·‘é€šè®­ç»ƒé—­ç¯ï¼Œé‡ç‚¹æ”¾åœ¨ï¼š

1. **routing / top-k**ï¼šgate å¯¹æ¯ä¸ª token é€‰æ‹© top-k ä¸“å®¶ï¼›
2. **dispatchï¼ˆAll-to-Allï¼‰**ï¼šæŠŠ token æ´¾å‘åˆ°â€œä¸“å®¶æ‰€åœ¨çš„ rankâ€ï¼›
3. **local expert forward**ï¼šæ¯ä¸ª rank åªè®¡ç®—è‡ªå·±æŒæœ‰çš„æœ¬åœ°ä¸“å®¶ï¼›
4. **combineï¼ˆAll-to-Allï¼‰**ï¼šæŠŠä¸“å®¶è¾“å‡ºå›ä¼ åˆ°æº rankï¼Œå¹¶æŒ‰ top-k æƒé‡èšåˆå› token åºåˆ—ï¼›
5. **è®­ç»ƒé—­ç¯**ï¼šåå‘ä¼ æ’­ç©¿è¿‡ gate + experts + é€šä¿¡ç®—å­ï¼ˆè¿™é‡Œç”¨ autograd-aware çš„ dist.all_gather å®ç°ï¼‰ã€‚

å®ç°é‡Œ ataï¼ˆall-to-allï¼‰ç®—å­å‚è€ƒäº†è¿™ä¸ª [reference](https://github.com/gpu-mode/reference-kernels/blob/eff169759596326890b23d4625cb6d5923266e55/problems/amd_distributed/all2all/reference.py#L54)

è¯´æ˜ï¼šå®Œæ•´çš„é«˜æ€§èƒ½ MoE/EP è®­ç»ƒæ˜¾ç„¶æœ‰æ›´å¤šä¼˜åŒ–ç©ºé—´ï¼Œä¾‹å¦‚ï¼š
* æ›´ç³»ç»Ÿçš„åˆ†å¸ƒå¼å¼ é‡/æ¢¯åº¦ç®¡ç†æˆ–è€…å¹¶è¡Œï¼ˆæ¯”å¦‚ DTensorï¼‰
* è®¡ç®—é€šä¿¡å¹¶è¡Œæ©ç›–é€šä¿¡å¼€é”€ï¼šTBOä½¿ç”¨åŒbatché‡å æ¥æ©ç›–å¤šæœºå¤šå¡Ataé€šä¿¡å¼€é”€ï¼›Deepseekæå‡ºçš„Shared Expertsçš„è®¡ç®—ä¹Ÿå¯ä»¥å’Œdispatché€šä¿¡å¹¶è¡Œé‡å ã€‚
* é«˜æ•ˆé€šä¿¡ï¼šataé€šä¿¡ä¸­å­˜åœ¨è¾ƒå¤§çš„é€šä¿¡å†—ä½™ï¼Œæ‹¿æˆ‘ä»¬æœ€ä¸Šé¢çš„é‚£å¼ å›¾æ¥è¯´æ˜ï¼š
    * åŒä¸€ä¸ª token dispatch åˆ°åŒä¸€å° device çš„ä¸åŒ expert ï¼ˆå¦‚ token2 dispatch åˆ° device 2 çš„ ä¸¤ä¸ª expert)ã€‚
    * åŒä¸€ä¸ª token dispatch åˆ°åŒä¸€å° host çš„ ä¸åŒ device (å¦‚ token2 dispatch åˆ° device 3 å’Œ device 4)ã€‚è¿™ç‚¹å¯ä»¥ç”±ä¸€æ¬¡æœºé—´é€šä¿¡åŠ æœºå†…é€šä¿¡æ›¿ä»£æ¥å‡å°‘æœºé—´é€šä¿¡ã€‚

åœ¨è¿™ä¸ªNotebooké‡Œï¼Œæˆ‘ä»¬ä»¥â€œå¯è¯» + å¯è·‘é€šâ€ä¸ºç›®æ ‡ï¼Œå…ˆæŠŠæ ¸å¿ƒæ•°æ®æµå’Œé€šä¿¡é€»è¾‘å†™æ¸…æ¥šã€‚

> å°æç¤ºï¼šæœ¬ notebook æœ€åä¸€ä¸ª cell ä¼šç”¨ `torchrun` å¯åŠ¨å¤šè¿›ç¨‹è®­ç»ƒã€‚å› ä¸º `torchrun` æ˜¯æ–°è¿›ç¨‹ï¼Œå®ƒä¸ä¼šå…±äº« notebook å†…å­˜ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼šä» notebook ä¸­æŠ½å–è‹¥å¹² code cell æ‹¼æˆä¸´æ—¶è„šæœ¬å†è¿è¡Œã€‚

## ç¯å¢ƒæ£€æŸ¥

ç¯å¢ƒæœ‰å¤šé‡è¦æƒ³å¿…ä¸å¿…å¤šè¯´

```
import os
import torch

# æ£€æµ‹ GPU æ•°é‡
gpu_count = torch.cuda.device_count()
print(f"æ£€æµ‹åˆ° {gpu_count} ä¸ª GPU")

if gpu_count >= 2:
    print(f"âœ… å¤š GPU ç¯å¢ƒï¼Œå°†ä½¿ç”¨ torchrun å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ (å»ºè®®ä½¿ç”¨ {gpu_count} ä¸ª GPU)")
    print("ğŸ“ åç»­å®éªŒå°†é€šè¿‡ %%writefile åˆ›å»ºä¸´æ—¶è„šæœ¬ï¼Œè‡ªåŠ¨è¿è¡Œ torchrunï¼Œå¹¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
else:
    print("âš ï¸  è­¦å‘Š: æ£€æµ‹åˆ°å°‘äº 2 ä¸ª GPUï¼Œåˆ†å¸ƒå¼è®­ç»ƒå¯èƒ½æ— æ³•æ­£å¸¸è¿è¡Œ")

print(f"\n å®éªŒé…ç½®:")
print(f"  - GPU æ•°é‡: {gpu_count}")
print(f"  - CUDA å¯ç”¨: {torch.cuda.is_available()}")
print(f"  - PyTorch ç‰ˆæœ¬: {torch.__version__}")
```

```
æ£€æµ‹åˆ° 2 ä¸ª GPU
âœ… å¤š GPU ç¯å¢ƒï¼Œå°†ä½¿ç”¨ torchrun å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ (å»ºè®®ä½¿ç”¨ 2 ä¸ª GPU)
ğŸ“ åç»­å®éªŒå°†é€šè¿‡ %%writefile åˆ›å»ºä¸´æ—¶è„šæœ¬ï¼Œè‡ªåŠ¨è¿è¡Œ torchrunï¼Œå¹¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶

 å®éªŒé…ç½®:
  - GPU æ•°é‡: 2
  - CUDA å¯ç”¨: True
  - PyTorch ç‰ˆæœ¬: 2.3.0+cu121
```

## åŸºæœ¬ç»„ä»¶å®ç°

### class MoEConfig

å…ˆå®šä¹‰ä¸€ä¸ª `MoEConfig`ï¼Œç»Ÿä¸€ç®¡ç† EP-MoE é‡Œæœ€å…³é”®çš„è¶…å‚æ•°ï¼š

- `num_experts`ï¼šå…¨å±€ä¸“å®¶æ€»æ•°ï¼ˆæ‰€æœ‰ rank ä¸Šä¸“å®¶çš„æ€»å’Œï¼‰ã€‚
- `experts_per_token`ï¼šæ¯ä¸ª token é€‰æ‹©çš„ä¸“å®¶ä¸ªæ•°ï¼ˆtop-kï¼‰ã€‚
- `hidden_dim`ï¼štoken hidden sizeï¼Œä¹Ÿæ˜¯ä¸“å®¶ MLP çš„è¾“å…¥/è¾“å‡ºç»´åº¦ã€‚
- `max_num_tokens`ï¼šç”¨äºé€šä¿¡ buffer çš„ä¸Šç•Œï¼ˆéœ€è¦èƒ½è¦†ç›–æœ¬ rank ä¸€æ¬¡å‰å‘é‡Œå¯èƒ½å‡ºç°çš„ token æ•°ï¼‰ã€‚
- `in_dtype/out_dtype`ï¼šè¾“å…¥/è¾“å‡º dtypeï¼ˆå®ç°é‡Œä¼šåœ¨ä¸“å®¶è®¡ç®—æ—¶ä¸´æ—¶è½¬æˆ `float32` ä»¥ç®€åŒ–æ•°å€¼é—®é¢˜ï¼‰ã€‚

çº¦æŸ/æ³¨æ„ï¼š
- è®­ç»ƒæ—¶å¦‚æœ `bsz`ï¼ˆæˆ– token æ•°ï¼‰è¶…è¿‡ `max_num_tokens`ï¼Œéœ€è¦å¢å¤§ `max_num_tokens`ï¼Œå¦åˆ™åé¢ä¼šå‡ºç° buffer ä¸å¤Ÿçš„æƒ…å†µã€‚
- `num_experts` å¿…é¡»èƒ½è¢« `world_size` æ•´é™¤ï¼ˆæ¯ä¸ª rank æ‹¥æœ‰åŒæ ·æ•°é‡çš„æœ¬åœ°ä¸“å®¶ï¼‰ã€‚


```
import dataclasses
import torch

@dataclasses.dataclass
class MoEConfig:
    num_experts: int
    experts_per_token: int
    hidden_dim: int
    max_num_tokens: int
    in_dtype: torch.dtype = torch.float16
    out_dtype: torch.dtype = torch.float16
```

### class PyTorchAllToAll

è¿™éƒ¨åˆ†å®ç° EP æœ€æ ¸å¿ƒçš„é€šä¿¡ç®—å­ï¼ˆata / all-to-allï¼‰çš„ä¸€ä¸ªâ€œæ•™å­¦ç‰ˆâ€ã€‚

**ä¸ºä»€ä¹ˆä¸ç”¨ `all_to_all_single`ï¼Ÿ**
- `torch.distributed.all_to_all_single` çš„è¯­ä¹‰éå¸¸è´´åˆ MoEï¼šå®ƒå¤©ç„¶æ”¯æŒæ¯ä¸ª rank å‘/æ”¶ä¸ç­‰é•¿åˆ†ç‰‡ï¼ˆsplit sizesï¼‰ï¼Œå¯¹åº”â€œä¸åŒä¸“å®¶æ”¶åˆ°ä¸åŒ token æ•°é‡â€çš„ç°å®æƒ…å†µã€‚
- ä½†`all_to_all_single`ä»…æ”¯æŒä¼ é€’dataï¼Œè€Œä¸ä¼ é€’gradï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨è®­ç»ƒåœºæ™¯å¹¶ä¸é€‚ç”¨ã€‚ï¼ˆå¯ä»¥è‡ªå·±å†™ä¸ªè„šæœ¬checkä¸€ä¸‹ï¼‰
- è¿™é‡Œé€‰æ‹©äº† **pad + `dist.nn.functional.all_gather`** çš„å®ç°ï¼šæŠŠæ¯ä¸ª rank çš„å‘é€æ¡ç›® pad åˆ°åŒæ ·é•¿åº¦ï¼Œå† gather åæŒ‰ meta è¿‡æ»¤ã€‚

**æ ¸å¿ƒæ•°æ®ç»“æ„ï¼šbuffer + metadata**
- bufferï¼šå­˜ token hiddenï¼ˆå½¢çŠ¶è¿‘ä¼¼ `[num_items, hidden_dim]`ï¼‰ã€‚
- metadataï¼šä¸ºæ¯æ¡ token è®°å½•â€œè½¨è¿¹â€ï¼Œä»¥ä¾¿ combine æ—¶æŠŠç»“æœæ”¾å›æ­£ç¡®ä½ç½®ã€‚è¿™é‡Œç”¨ `META_DIM=5`ï¼š

| å­—æ®µ | å«ä¹‰ | ä½œç”¨ |
|---|---|---|
| `global_exp` | å…¨å±€ä¸“å®¶ ID | å†³å®š token åº”è¯¥æ´¾å‘åˆ°å“ªä¸ª rank/å“ªä¸ªæœ¬åœ° expert |
| `src_rank` | æº rank | combine æ—¶å†³å®šå›ä¼ åˆ°å“ªä¸ª rank |
| `src_token` | æº token ä¸‹æ ‡ | combine æ—¶å›å¡«åˆ°å“ªä¸ª token ä½ç½® |
| `src_k` | top-k åºå· | combine æ—¶å– `weights[token, k]` åšåŠ æƒ |
| `pad` | padding æ ‡è®°/å ä½ | è¿™é‡Œç®€åŒ–ä¸º 0ï¼Œå ä½å³å¯ |

**dispatch çš„è¾“å…¥/è¾“å‡ºï¼ˆæ¦‚å¿µä¸Šï¼‰**
- è¾“å…¥ï¼š
  - `dp_x`: å½“å‰ rank çš„ tokenï¼Œshape `[num_tokens, hidden_dim]`
  - `indices`: æ¯ä¸ª token é€‰ä¸­çš„ä¸“å®¶ IDï¼Œshape `[num_tokens, topk]`
- è¾“å‡ºï¼ˆè½æ¡¶åˆ°æœ¬åœ°ä¸“å®¶ï¼‰ï¼š
  - `expert_num_tokens`: shape `[num_local_experts]`
  - `expert_x`: shape `[num_local_experts, max_recv, hidden_dim]`ï¼ˆæŒ‰æœ¬åœ° expert åˆ†æ¡¶åçš„è¾“å…¥ï¼‰
  - `expert_meta`: shape `[num_local_experts, max_recv, META_DIM]`

**å®ç°ä¸Šçš„é‡è¦å–èˆï¼ˆä¹Ÿæ­£æ˜¯æ€§èƒ½ç“¶é¢ˆæ¥æºï¼‰**
- éœ€è¦æŠŠå‘é€æ¡ç›® pad åˆ°ç»Ÿä¸€é•¿åº¦ï¼Œå¯¼è‡´é¢å¤–é€šä¿¡/æ‹·è´ï¼ˆå¯¹è´Ÿè½½ä¸å‡æ—¶å°¤å…¶æ˜æ˜¾ï¼‰ã€‚
- é€šè¿‡ Python å¾ªç¯ç»„è£…/è½æ¡¶ï¼ˆè€Œä¸æ˜¯å‘é‡åŒ–/èåˆ kernelï¼‰ï¼Œå¼€é”€åå¤§ã€‚
- è¿™æ˜¯ä¸ºäº†æŠŠâ€œæ•°æ®å¦‚ä½•æµåŠ¨â€è¯´æ¸…æ¥šï¼›åœ¨æ€»ç»“é‡Œä¼šåˆ—å‡ºæ›´è´´è¿‘çœŸå®è®­ç»ƒçš„ä¼˜åŒ–æ–¹å‘ã€‚

```
# pytorch_all2all.py
import torch.distributed as dist
import torch.distributed.nn.functional as dist_nn

# ---------------- All2All pytorch impl ----------------
class PyTorchAllToAll:
    META_DIM = 5  # global_exp, src_rank, src_token, src_k, pad

    # åˆå§‹åŒ–ä¸€äº›åˆ†å¸ƒå¼éœ€è¦çš„å˜é‡
    def __init__(self, cfg: MoEConfig, rank: int, world_size: int):
        self.cfg = cfg
        self.rank = rank
        self.world_size = world_size
        # num experts per rank
        self.num_local_experts = cfg.num_experts // world_size
        # max recv tokens per rankï¼Œä¸æ»¡è¶³çš„ç”¨ padding
        self.max_recv = cfg.max_num_tokens * world_size

    # ---------- dispatch ----------
    # dp_x å½“å‰ rankï¼ˆgpuï¼‰æ‹¥æœ‰çš„ tokenï¼Œshape = [num_tokens,hidden_dim]
    # indices: æ¯ä¸ª token é€‰ä¸­çš„å…¨å±€ä¸“å®¶IDåˆ—è¡¨ï¼Œå½¢çŠ¶ [num_tokens, experts_per_token]ï¼Œå€¼åŸŸ [0, num_experts)ã€‚
    # TODO experts_per_token å°±æ˜¯ topkï¼Œèƒ½ä¸èƒ½æ”¹æˆ topkï¼Ÿå¹¶ä¸”ä½œä¸ºä¸€ä¸ªå¯ä»¥ä»å¤–éƒ¨ä¼ å…¥çš„å‚æ•°ã€‚
    def dispatch(self, dp_x: torch.Tensor, indices: torch.Tensor):
        device = dp_x.device
        cfg = self.cfg

        # 1) æ„å»ºæ‰å¹³çš„å‘é€ buffer ä¸ meta
        send_tokens = []
        send_meta = []
        for t, expert_list in enumerate(indices.tolist()):
            for k, e in enumerate(expert_list):
                send_tokens.append(dp_x[t].unsqueeze(0))
                send_meta.append([e, self.rank, t, k, 0])
        if send_tokens:
            send_buf_flat = torch.cat(send_tokens, dim=0)
            send_meta_flat = torch.tensor(send_meta, device=device, dtype=torch.int32)
        else:
            send_buf_flat = torch.empty((0, cfg.hidden_dim), device=device, dtype=cfg.in_dtype)
            send_meta_flat = torch.empty((0, self.META_DIM), device=device, dtype=torch.int32)

        # 2) äº¤æ¢å„ rank å‘é€æ¡æ•°ï¼Œpad åˆ°ç»Ÿä¸€é•¿åº¦
        # è¿™æ ·åé¢å¯ä»¥ç”¨ all_gatherï¼ˆè¦æ±‚å„ rank tensor å½¢çŠ¶ä¸€è‡´ï¼‰æ¥å®ç°å¯åä¼ çš„é€šä¿¡ã€‚
        send_items = torch.tensor([send_meta_flat.size(0)], device=device, dtype=torch.long)
        all_items = [torch.zeros_like(send_items) for _ in range(self.world_size)]
        dist.all_gather(all_items, send_items)
        send_counts = [int(c.item()) for c in all_items]
        max_items = max(send_counts)
        pad_len = max_items - send_meta_flat.size(0)
        if pad_len > 0:
            pad_buf = torch.zeros(pad_len, cfg.hidden_dim, device=device, dtype=cfg.in_dtype)
            pad_meta = torch.zeros(pad_len, self.META_DIM, device=device, dtype=torch.int32)
            send_buf_flat = torch.cat([send_buf_flat, pad_buf], dim=0)
            send_meta_flat = torch.cat([send_meta_flat, pad_meta], dim=0)

        # 3) all_gather æ•°æ®ä¸ metaï¼ˆautograd-awareï¼‰
        gathered_buf = dist_nn.all_gather(send_buf_flat)
        gathered_meta = dist_nn.all_gather(send_meta_flat)
        concat_buf = torch.cat(gathered_buf, dim=0)
        concat_meta = torch.cat(gathered_meta, dim=0)

        # 4) è¿‡æ»¤ç›®æ ‡ä¸ºæœ¬ rank çš„æ¡ç›®ï¼ˆæ ¹æ®å…¨å±€ä¸“å®¶ ID æ˜ å°„ rankï¼‰
        global_eids = concat_meta[:, 0].to(torch.long)
        dst_ranks = global_eids // self.num_local_experts
        mask = dst_ranks == self.rank
        valid_buf = concat_buf[mask]
        valid_meta = concat_meta[mask]
        total_recv = valid_buf.size(0)

        # 5) è½æ¡¶åˆ°æœ¬åœ°ä¸“å®¶
        expert_num_tokens = torch.zeros(self.num_local_experts, dtype=torch.int32, device=device)
        expert_x = torch.empty(
            (self.num_local_experts, self.max_recv, cfg.hidden_dim),
            dtype=cfg.in_dtype,
            device=device,
        )
        expert_meta = torch.empty(
            (self.num_local_experts, self.max_recv, self.META_DIM),
            dtype=torch.int32,
            device=device,
        )
        for i in range(total_recv):
            geid = int(valid_meta[i, 0].item())
            local_eid = geid % self.num_local_experts
            pos = expert_num_tokens[local_eid]
            expert_x[local_eid, pos] = valid_buf[i]
            expert_meta[local_eid, pos] = valid_meta[i]
            expert_num_tokens[local_eid] += 1

        return expert_num_tokens, expert_x, expert_meta

    # ---------- combine ----------
    def combine(
        self,
        out_tokens: torch.Tensor,  # output, (max num tokens, hidden_dim)
        weights: torch.Tensor,  # topk weight
        expert_meta: torch.Tensor,  # input
        expert_y: torch.Tensor,  # input, (num_local_experts, max_num_tokens * num_dp, hidden_dim)
        expert_num_tokens: torch.Tensor,
    ):  # input
        device = out_tokens.device
        cfg = self.cfg

        # å•æœºå•å¡ç›´æ¥èšåˆï¼Œé¿å…é€šä¿¡å†™å…¥ç ´åè®¡ç®—å›¾
        if self.world_size == 1:
            total_recv = int(expert_num_tokens.sum().item())
            if total_recv == 0:
                return out_tokens
            idx = []
            upd = []
            for local_eid in range(self.num_local_experts):
                cnt = int(expert_num_tokens[local_eid].item())
                for j in range(cnt):
                    meta = expert_meta[local_eid, j]
                    src_token = int(meta[2].item())
                    src_k = int(meta[3].item())
                    w = weights[src_token, src_k].to(torch.float32)
                    idx.append(src_token)
                    upd.append(expert_y[local_eid, j].to(torch.float32) * w)
            idx = torch.tensor(idx, device=device, dtype=torch.long)
            updates = torch.stack(upd, dim=0)
            out = torch.zeros_like(out_tokens, dtype=torch.float32)
            out = out.index_add(0, idx, updates)
            out = out + out_tokens.to(torch.float32)
            return out.to(out_tokens.dtype)

        # æ„å»ºæ‰å¹³çš„å‘é€ buffer ä¸ metaï¼ˆç›®æ ‡ rank = meta[:,1]ï¼‰
        send_tokens = []
        send_meta = []
        for local_eid in range(self.num_local_experts):
            cnt = int(expert_num_tokens[local_eid].item())
            if cnt == 0:
                continue
            send_tokens.append(expert_y[local_eid, :cnt])
            send_meta.append(expert_meta[local_eid, :cnt])
        if send_tokens:
            send_buf_flat = torch.cat(send_tokens, dim=0)
            send_meta_flat = torch.cat(send_meta, dim=0)
        else:
            send_buf_flat = torch.empty((0, cfg.hidden_dim), device=device, dtype=cfg.out_dtype)
            send_meta_flat = torch.empty((0, self.META_DIM), device=device, dtype=torch.int32)

        # 1) äº¤æ¢æ¡æ•°ï¼Œpad åˆ°ç»Ÿä¸€é•¿åº¦
        send_items = torch.tensor([send_meta_flat.size(0)], device=device, dtype=torch.long)
        all_items = [torch.zeros_like(send_items) for _ in range(self.world_size)]
        dist.all_gather(all_items, send_items)
        send_counts = [int(c.item()) for c in all_items]
        max_items = max(send_counts)
        pad_len = max_items - send_meta_flat.size(0)
        if pad_len > 0:
            pad_buf = torch.zeros(pad_len, cfg.hidden_dim, device=device, dtype=cfg.out_dtype)
            pad_meta = torch.zeros(pad_len, self.META_DIM, device=device, dtype=torch.int32)
            send_buf_flat = torch.cat([send_buf_flat, pad_buf], dim=0)
            send_meta_flat = torch.cat([send_meta_flat, pad_meta], dim=0)

        # 2) all_gather æ•°æ®å’Œå…ƒä¿¡æ¯
        gathered_buf = dist_nn.all_gather(send_buf_flat)
        gathered_meta = dist_nn.all_gather(send_meta_flat)
        concat_buf = torch.cat(gathered_buf, dim=0)
        concat_meta = torch.cat(gathered_meta, dim=0)

        # 3) è¿‡æ»¤ç›®æ ‡ä¸ºæœ¬ rank çš„æ¡ç›®ï¼ˆmeta[1] æ˜¯ src_rankï¼Œä½œä¸ºå›ä¼ ç›®çš„åœ°ï¼‰
        dst_mask = concat_meta[:, 1].to(torch.long) == self.rank
        if not torch.any(dst_mask):
            return out_tokens
        recv_buf = concat_buf[dst_mask]
        recv_meta = concat_meta[dst_mask]

        # 4) èšåˆå›æº token
        idx = recv_meta[:, 2].to(torch.long)      # src_token
        src_k = recv_meta[:, 3].to(torch.long)    # topk åºå·
        weight = weights[idx, src_k].to(torch.float32)
        updates = recv_buf.to(torch.float32) * weight.unsqueeze(1)

        out = torch.zeros_like(out_tokens, dtype=torch.float32)
        out = out.index_add(0, idx, updates)
        out = out + out_tokens.to(torch.float32)
        return out.to(out_tokens.dtype)
```

### class Expert and class EPMoE

è¿™é‡Œå®šä¹‰ï¼š
- `Expert`ï¼šå•ä¸ªä¸“å®¶ï¼ˆç”¨ä¸¤å±‚ MLP ä»£è¡¨ï¼‰ã€‚
- `EPMoE`ï¼šEP å¹¶è¡Œçš„ MoE layerï¼ŒåŒ…å« gateã€ä¸“å®¶åˆ†ç‰‡ã€dispatch/combineã€‚

ä¸ºäº†é˜…è¯»æ–¹ä¾¿ï¼Œå¯ä»¥æŠŠä¸€æ¬¡å‰å‘ç†è§£æˆ 5 æ­¥ï¼š

1. **gate + top-k**ï¼š`gate(x)` å¾—åˆ°æ¯ä¸ª token å¯¹æ¯ä¸ªä¸“å®¶çš„æ‰“åˆ†ï¼Œsoftmax åå– top-kï¼Œå¾—åˆ°ï¼š
   - `indices`: `[num_tokens, topk]`ï¼ˆæ¯ä¸ª token é€‰ä¸­çš„å…¨å±€ä¸“å®¶ IDï¼‰
   - `weights`: `[num_tokens, topk]`ï¼ˆå¯¹åº”çš„æ¦‚ç‡/æƒé‡ï¼‰
2. **aux lossï¼ˆè´Ÿè½½å‡è¡¡ï¼‰**ï¼šè®­ç»ƒæ—¶é¢å¤–è¿”å›ä¸€ä¸ªè¾…åŠ©æŸå¤±ï¼Œé¼“åŠ±è·¯ç”±æ›´å‡åŒ€ï¼Œé¿å…å°‘æ•°ä¸“å®¶è¿‡è½½ã€‚
3. **dispatch**ï¼šæŒ‰ `indices` æŠŠ token å‘åˆ°â€œä¸“å®¶æ‰€åœ¨ rankâ€ã€‚
4. **local expert forward**ï¼šæ¯ä¸ª rank åªå¯¹è‡ªå·±çš„æœ¬åœ°ä¸“å®¶åšå‰å‘ï¼ˆåªç®—æœ¬åœ°å‚æ•°ï¼‰ã€‚
5. **combine**ï¼šæŠŠä¸“å®¶è¾“å‡ºæŒ‰ `expert_meta` å›ä¼ åˆ°æº rankï¼Œå¹¶æŒ‰ `weights` èšåˆå› token åºåˆ—ã€‚

å®ç°ç»†èŠ‚/æ³¨æ„ï¼š
- `weights` ç”¨ `float32` åšåŠ æƒï¼Œé¿å…åŠç²¾åº¦ä¸‹ç´¯åŠ è¯¯å·®æ”¾å¤§ã€‚
- å•å¡è·¯å¾„ï¼ˆ`world_size==1`ï¼‰ä¸“é—¨åšäº†ä¸€æ¡â€œæ— é€šä¿¡â€çš„åˆ†æ”¯ï¼šæ—¢é¿å…é€šä¿¡å¼€é”€ï¼Œä¹Ÿå°½é‡ä¿ä½ autograd å›¾ã€‚
- å¤šå¡è·¯å¾„ç”¨ `PyTorchAllToAll` ä½œä¸ºé€šä¿¡åç«¯ã€‚

```
import torch.nn as nn
import torch.distributed as dist

# ä¸“å®¶æ¨¡å—
class Expert(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.GELU(),  
            nn.Linear(hidden_dim, output_dim))
        
    def forward(self, x):
        return self.net(x)  

class EPMoE(nn.Module):
    """
    Expert-Parallel MoE layer.

    - gate: replicated across ranks (wrap with DDP outside if world_size > 1)
    - experts: sharded across ranks (each rank owns num_experts/world_size experts)
    - comm: dispatch/combine via PyTorchAllToAll
    """

    def __init__(self, cfg: MoEConfig, rank: int | None = None, world_size: int | None = None):
        super().__init__()
        self.cfg = cfg
        self.rank = dist.get_rank() if rank is None else rank
        self.world_size = dist.get_world_size() if world_size is None else world_size

        if cfg.num_experts % self.world_size != 0:
            raise ValueError("num_experts must be divisible by world_size")

        # ATAï¼ˆall-to-allï¼‰é€šä¿¡ç®—å­ï¼šè´Ÿè´£ EP çš„ token æ´¾å‘ï¼ˆdispatchï¼‰ä¸å›æ”¶ï¼ˆcombineï¼‰
        self.ata = PyTorchAllToAll(cfg, rank=self.rank, world_size=self.world_size)
        # gate åœ¨æ¯ä¸ª rank éƒ½æœ‰ä¸€ä»½ï¼›è®­ç»ƒæ—¶å»ºè®®åœ¨å¤–éƒ¨ç”¨ DDP åŒ…èµ·æ¥åšå‚æ•°/æ¢¯åº¦åŒæ­¥
        self.gate = nn.Linear(cfg.hidden_dim, cfg.num_experts)

        # experts æŒ‰ rank åˆ†ç‰‡ï¼šæ¯ä¸ª rank åªæ‹¥æœ‰ num_local_experts ä¸ªä¸“å®¶å‚æ•°
        self.num_local_experts = cfg.num_experts // self.world_size
        self.experts = nn.ModuleList(
            [Expert(cfg.hidden_dim, cfg.hidden_dim * 4, cfg.hidden_dim) for _ in range(self.num_local_experts)]
        )

    def _aux_loss(self, probs: torch.Tensor, indices: torch.Tensor) -> torch.Tensor:
        cfg = self.cfg
        # è´Ÿè½½å‡è¡¡è¾…åŠ©æŸå¤±ï¼ˆå’Œ my_moe/layers/moe_layer.py ä¿æŒä¸€è‡´ï¼‰
        # ç›®çš„ï¼šé¿å… gate æŠŠ token è¿‡åº¦è·¯ç”±åˆ°å°‘æ•°ä¸“å®¶ï¼Œå¯¼è‡´ä¸“å®¶â€œå¿™é—²ä¸å‡â€
        importance = probs.sum(0)  # [num_experts]
        importance_loss = torch.var(importance) / (cfg.num_experts**2)
        mask = torch.zeros_like(probs, dtype=torch.bool)
        mask.scatter_(1, indices, True)
        routing_probs = probs * mask
        expert_usage = mask.float().mean(0)
        routing_weights = routing_probs.mean(0)
        load_balance_loss = cfg.num_experts * (expert_usage * routing_weights).sum()
        return importance_loss + load_balance_loss

    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        cfg = self.cfg
        # 1) routingï¼šè®¡ç®—æ¯ä¸ª token å¯¹æ¯ä¸ªä¸“å®¶çš„åŒ¹é…åˆ†æ•°ï¼Œç„¶åå– top-k ä¸“å®¶
        logits = self.gate(x)
        probs = torch.softmax(logits, dim=-1)
        weights, indices = torch.topk(probs, cfg.experts_per_token, dim=-1)
        # indices: ä¸“å®¶ IDï¼›weights: å¯¹åº”æ¦‚ç‡ï¼ˆåç»­ combine ä¼šæŒ‰ weights åŠ æƒèšåˆï¼‰
        indices = indices.to(torch.int64)
        weights = weights.to(torch.float32)

        # 2) aux lossï¼šè®­ç»ƒæ—¶è¿”å›ï¼Œæ¨ç†æ—¶ä¸º 0
        aux_loss = self._aux_loss(probs, indices) if self.training else torch.tensor(0.0, device=x.device)

        # 3) dispatchï¼šæŠŠ token æ ¹æ®â€œä¸“å®¶æ‰€åœ¨ rankâ€æ´¾å‘å‡ºå»
        #    - å•å¡ï¼šä¸èµ°é€šä¿¡ï¼Œç›´æ¥åœ¨æœ¬åœ°æŒ‰ä¸“å®¶åˆ†æ¡¶ï¼ˆä¿ç•™å¯¹ x çš„è®¡ç®—å›¾ï¼‰
        #    - å¤šå¡ï¼šèµ° ATA dispatchï¼ˆall_to_all / all_gather ç­‰å®ç°ç»†èŠ‚åœ¨ reference.pyï¼‰
        if self.world_size == 1:
            token_map = [[] for _ in range(self.ata.num_local_experts)]
            for t, expert_list in enumerate(indices.tolist()):
                for k, e in enumerate(expert_list):
                    local_eid = e % self.ata.num_local_experts
                    token_map[local_eid].append((t, k, e))

            expert_num = torch.tensor([len(lst) for lst in token_map], device=x.device, dtype=torch.int32)
            # expert_meta: æ¯æ¡æ´¾å‘ token çš„å…ƒä¿¡æ¯ï¼ˆç”¨äº combine å›å¡«ï¼‰
            # META_DIM=5: [global_exp, src_rank, src_token, src_k, pad]
            expert_meta = torch.zeros(
                (self.ata.num_local_experts, self.ata.max_recv, self.ata.META_DIM),
                device=x.device,
                dtype=torch.int32,
            )
            expert_inputs = []
            for local_eid, lst in enumerate(token_map):
                for pos, (t, k, e) in enumerate(lst):
                    expert_meta[local_eid, pos, 0] = e
                    expert_meta[local_eid, pos, 1] = self.rank
                    expert_meta[local_eid, pos, 2] = t
                    expert_meta[local_eid, pos, 3] = k
                idx = [t for t, _, _ in lst]
                expert_inputs.append(x[idx] if idx else None)
            expert_x = None
        else:
            expert_num, expert_x, expert_meta = self.ata.dispatch(x, indices)
            expert_inputs = None

        # 4) local expert forwardï¼šæ¯ä¸ª rank åªè®¡ç®—è‡ªå·±æŒæœ‰çš„æœ¬åœ°ä¸“å®¶
        expert_y = torch.zeros(
            (self.ata.num_local_experts, self.ata.max_recv, cfg.hidden_dim),
            device=x.device,
            dtype=cfg.out_dtype,
        )
        # TODOï¼šè¿™ä¸ªåœ°æ–¹å¯ä»¥ç”¨bmmä»£æ›¿å¾ªç¯ï¼Œè·å¾—å¤§å¹…ä¼˜åŒ–
        for local_eid in range(self.ata.num_local_experts):
            cnt = int(expert_num[local_eid].item())
            if cnt == 0:
                continue
            if self.world_size == 1:
                x_slice = expert_inputs[local_eid].to(torch.float32)
            else:
                x_slice = expert_x[local_eid, :cnt].to(torch.float32)
            y_slice = self.experts[local_eid](x_slice).to(cfg.out_dtype)
            expert_y[local_eid, :cnt] = y_slice

        # 5) combineï¼šæŠŠä¸“å®¶è¾“å‡ºæŒ‰ meta å›ä¼ åˆ°åŸ rankï¼Œå¹¶æŒ‰ top-k æƒé‡åŠ æƒèšåˆå› token åºåˆ—
        out_tokens = torch.zeros(cfg.max_num_tokens, cfg.hidden_dim, device=x.device, dtype=cfg.out_dtype)
        out_tokens = self.ata.combine(out_tokens, weights, expert_meta, expert_y, expert_num)
        out_tokens = out_tokens[: x.shape[0]]
        return out_tokens, aux_loss
```

## è®­ç»ƒ

è¿™ä¸€èŠ‚ç”¨ä¸€ä¸ª toy ä»»åŠ¡æŠŠè®­ç»ƒé—­ç¯è·‘é€šï¼Œç›®æ ‡ä¸æ˜¯â€œé«˜æ•ˆè®­ç»ƒå‡ºå¥½æ¨¡å‹â€ï¼Œè€Œæ˜¯éªŒè¯ï¼š

- gate çš„è·¯ç”±ï¼ˆtop-kï¼‰èƒ½å·¥ä½œï¼›
- ataç®—å­åˆ†å¸ƒå¼é€šä¿¡å·¥ä½œæ­£å¸¸ï¼š
    - token èƒ½æ­£ç¡® dispatch åˆ°ä¸“å®¶æ‰€åœ¨ rankï¼Œä¸“å®¶ç®—å®Œèƒ½æ­£ç¡® combine å›æ¥ï¼›
    - åå‘ä¼ æ’­èƒ½ç©¿è¿‡ gate / experts / é€šä¿¡è·¯å¾„ï¼›
- Lossæ­£å¸¸ä¸‹é™ï¼›æ—¥å¿—ä¸ tensorboard æŒ‡æ ‡èƒ½å¸®åŠ©æˆ‘ä»¬è§‚å¯Ÿ loss ä¸è€—æ—¶ã€‚

è®­ç»ƒè®¾ç½®ï¼š
- æ¨¡æ‹Ÿä»»åŠ¡ï¼šç”¨ `target_proj`ï¼ˆä¸€ä¸ªå›ºå®šçš„çº¿æ€§å±‚ï¼‰ç”Ÿæˆç›‘ç£ä¿¡å· `y`ï¼Œè®© MoE å»æ‹Ÿåˆè¿™ä¸ªæ˜ å°„ã€‚
- æ€»æŸå¤±ï¼š`task_loss + aux_alpha * aux_loss`ã€‚
- rank0 æ¯éš” `log_interval` æ‰“å°ä¸€æ¬¡ loss å’ŒåŒºé—´è€—æ—¶ï¼›åŒæ—¶å†™å…¥ tensorboardï¼ˆ`TB_LOGDIR`ï¼‰ã€‚

ä½ åº”è¯¥çœ‹åˆ°çš„ç°è±¡ï¼š
- `loss/task` ä¼šé€æ¸ä¸‹é™ï¼ˆtoy ä»»åŠ¡é€šå¸¸å¾ˆå¿«èƒ½ä¸‹é™ï¼‰ï¼›
- `loss/aux` çš„é‡çº§ä¸ `aux_alpha`/è·¯ç”±åˆ†å¸ƒæœ‰å…³ï¼Œä¸ä¸€å®šå•è°ƒï¼›

```
import os
import time
from torch.utils.tensorboard import SummaryWriter
from torch.nn.parallel import DistributedDataParallel as DDP


def init_distributed():
    """Init process group if not already done."""
    if dist.is_initialized():
        return
    backend = "nccl" if torch.cuda.is_available() else "gloo"
    dist.init_process_group(backend=backend)


def train_tiny_ep(
    cfg: MoEConfig,
    steps: int = 10,
    bsz: int = 16,
    lr: float = 5e-4,
    log_interval: int = 1000,
    aux_alpha: float = 1e-2,
    profile: bool = False,
):
    """Minimal EP-only training loop using EPMoE layer."""
    # åˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    # è®¾å¤‡åˆ†é…ï¼šcuda: 0, 1, ...
    device = (
        torch.device(f"cuda:{int(os.environ.get('LOCAL_RANK', 0))}")
        if torch.cuda.is_available()
        else torch.device("cpu")
    )
    if device.type == "cuda":
        torch.cuda.set_device(device.index)     # ç»‘å®šrankåˆ°å¯¹åº”çš„GPUè®¾å¤‡

    # ä½¿ç”¨EPMoEå±‚æ„å»ºæ¨¡å‹ï¼ˆåŒ…å«gateã€expertså’Œall-to-allé€šä¿¡ï¼‰
    model = EPMoE(cfg, rank=rank, world_size=world_size).to(device)
    if world_size > 1:
        model.gate = DDP(model.gate, device_ids=[device] if device.type == "cuda" else None)

    # è®­ç»ƒé…ç½®ï¼šä¼˜åŒ–å™¨ã€ç›®æ ‡å‡½æ•°å’Œç›‘æ§å·¥å…·
    opt = torch.optim.AdamW(list(model.gate.parameters()) + list(model.experts.parameters()), lr=lr)
    target_proj = torch.nn.Linear(cfg.hidden_dim, cfg.hidden_dim, bias=False).to(device)  # æ¨¡æ‹Ÿä»»åŠ¡ï¼šè®­ç»ƒMoEç½‘ç»œæ‹Ÿåˆçº¿æ€§å˜æ¢
    target_proj.requires_grad_(False)                                                       # ç›®æ ‡ç½‘ç»œä¸å‚ä¸è®­ç»ƒï¼Œä»…ç”¨äºç”Ÿæˆæ ‡ç­¾
    mse = torch.nn.MSELoss()
    writer = SummaryWriter(log_dir=os.environ.get("TB_LOGDIR")) if rank == 0 else None

    start_time = time.perf_counter()
    last_log_time = start_time
    for step in range(steps):
        # 1) ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        x = torch.randn(bsz, cfg.hidden_dim, device=device, dtype=cfg.in_dtype)
        with torch.no_grad():
            y = target_proj(x.float()).to(cfg.out_dtype)

        # 2) EPMoEå‰å‘è®¡ç®—ï¼ˆåŒ…å«è·¯ç”±ã€all-to-allé€šä¿¡ã€ä¸“å®¶è®¡ç®—å’Œç»“æœèšåˆï¼‰
        out_tokens, aux_loss = model(x)

        # 3) æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­
        task_loss = mse(out_tokens.float(), y)
        total_loss = task_loss + aux_alpha * aux_loss
        opt.zero_grad(set_to_none=True)
        total_loss.backward()
        opt.step()

        interval_s = None
        if rank == 0 and step % log_interval == 0:
            now = time.perf_counter()
            interval_s = 0.0 if step == 0 else (now - last_log_time)
            last_log_time = now
            print(
                f"[step {step:05d}] task={task_loss.item():.4f} aux={aux_loss.item():.4f} "
                f"total={total_loss.item():.4f} interval_s={interval_s:.2f}"
            )
        if writer:
            writer.add_scalar("loss/task", task_loss.item(), step)
            writer.add_scalar("loss/aux", aux_loss.item(), step)
            writer.add_scalar("loss/total", total_loss.item(), step)
            if interval_s is not None:
                writer.add_scalar("time/interval_s", interval_s, step)
    
    if profile and rank == 0:
        elapsed = time.perf_counter() - start_time
        print(f"[ep] total {steps} steps time: {elapsed:.2f}s | {elapsed/steps*1000:.2f} ms/step")

    dist.barrier()
    if writer:
        writer.flush()
        writer.close()
```

**é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ**

åœ¨ notebook é‡Œå¤šå¡è·‘è®­ç»ƒä¸æ–¹ä¾¿ï¼šå†…æ ¸é»˜è®¤ world-size=1ï¼Œä¸” torchrun å¯åŠ¨çš„æ–°è¿›ç¨‹æ— æ³•å…±äº« notebook å·²åŠ è½½çš„ä»£ç /å†…å­˜ã€‚

**æ€ä¹ˆè§£å†³çš„ï¼Ÿ**

* æˆ‘ä»¬ä» notebook æŠ½å–å¸¦ tag çš„å…³é”® code cellsï¼ˆå¦‚éƒ½æ‰“ moe_coreï¼Œæˆ–ç»†åˆ† tagsï¼‰ï¼Œæ‹¼æˆä¸´æ—¶ launcher.py
* ç„¶åç”¨ subprocess è°ƒ torchrun launcher.pyï¼Œè®©å®ƒè‡ªåŠ¨ spawn å¤šè¿›ç¨‹ã€‚
* ç”¨ tag æŠ½å–è€Œä¸æ˜¯å›ºå®šä¸‹æ ‡ï¼Œè¿™æ ·ä½ å¯ä»¥éšæ„æ’å…¥/è°ƒæ•´ markdown æˆ–å…¶ä»– cellsï¼Œä¸ä¼šå½±å“ launcher æŠ½å–ã€‚

è¿è¡Œæµç¨‹ï¼šåœ¨ notebook ä¸­è°ƒç”¨ torchrun --nproc_per_node=<N> launcher.pyï¼Œlauncher.py å†…éƒ¨ä¼š init_process_groupã€åˆ›å»ºæ¨¡å‹/è®­ç»ƒå¾ªç¯ï¼Œå®Œæˆåˆ†å¸ƒå¼è®­ç»ƒã€‚

```
# è¯´æ˜ï¼štorchrun ä¼š spawn æ–°è¿›ç¨‹æ‰§è¡Œä¸€ä¸ªâ€œè„šæœ¬æ–‡ä»¶â€ï¼Œä¸ä¼šå…±äº« notebook å†…å­˜ã€‚
# è¿™é‡Œç”¨æœ€ç®€å•çš„æ–¹å¼ï¼šè¯»å‡ºéœ€è¦çš„ code cell æ‹¼æˆä¸€ä¸ªè„šæœ¬ï¼Œç”¨ %%writefile å†™åˆ°å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ ep_launcher/launcher.pyï¼Œå† torchrun è·‘å®ƒã€‚

import json
import os
import subprocess
from pathlib import Path
from IPython import get_ipython

# notebook è·¯å¾„ï¼ˆæŒ‰å½“å‰ repo ç›¸å¯¹è·¯å¾„è¯»å–ï¼‰
NOTEBOOK_PATH = Path("CODE03DistMoE.ipynb")
TAG_LIST = ["moe_train"]

def _cells_by_tags(nb_path: Path, tags: list[str]) -> list[int]:
    nb = json.loads(nb_path.read_text(encoding="utf-8"))
    hit = []
    for i, c in enumerate(nb["cells"]):
        if c.get("cell_type") != "code":
            continue
        t = c.get("metadata", {}).get("tags", [])
        if any(tag in t for tag in tags):
            hit.append(i)
    return hit

cell_indices = _cells_by_tags(NOTEBOOK_PATH, TAG_LIST)
# print(cell_indices)

# åœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹ä½¿ç”¨å›ºå®šç›®å½•ï¼Œä¾¿äºä¿ç•™è„šæœ¬å’Œ tensorboard æ—¥å¿—
LAUNCH_DIR = Path.cwd() / "ep_launcher"
LAUNCH_DIR.mkdir(exist_ok=True)
SCRIPT_PATH = LAUNCH_DIR / "launcher.py"
LOG_DIR = LAUNCH_DIR / "runs"
LOG_DIR.mkdir(exist_ok=True)

moe_cfg = dict(
    num_experts=16,
    experts_per_token=2,
    hidden_dim=256,
    max_num_tokens=128,
)

train_cfg = dict(
    steps=10000,
    bsz=32,
    lr=5e-4,
    aux_alpha=1e-2,
    log_interval=1000,
    profile=False,
)

dist_cfg = dict(
    nproc_per_node=2,  # æ”¹æˆä½ çš„ GPU æ•°
)


def _read_cells_as_py(nb_path: Path, indices: list[int]) -> str:
    nb = json.loads(nb_path.read_text(encoding="utf-8"))
    parts = []
    for i in indices:
        parts.append("".join(nb["cells"][i]["source"]))
        parts.append("\n\n")
    return "".join(parts)


if not NOTEBOOK_PATH.exists():
    raise FileNotFoundError(f"æ‰¾ä¸åˆ° notebook: {NOTEBOOK_PATH}")

core = _read_cells_as_py(NOTEBOOK_PATH, cell_indices)

runner = f'''\\
import torch
import torch.distributed as dist

MOE_CFG = {moe_cfg!r}
TRAIN_CFG = {train_cfg!r}

def main():
    init_distributed()
    cfg = MoEConfig(**MOE_CFG, in_dtype=torch.float32, out_dtype=torch.float32)
    try:
        train_tiny_ep(cfg, **TRAIN_CFG)
        if dist.get_rank() == 0:
            print("EP MoE tiny training finished.")
    finally:
        dist.destroy_process_group()


if __name__ == "__main__":
    main()
'''

ip = get_ipython()
if ip is None:
    raise RuntimeError("éœ€è¦åœ¨ Jupyter/IPython ç¯å¢ƒä¸‹è¿è¡Œï¼ˆä¾èµ– %%writefile magicï¼‰ã€‚")

ip.run_cell_magic("writefile", str(SCRIPT_PATH), core + "\n\n" + runner)
print(f"Wrote launcher to {SCRIPT_PATH}")

cmd = [
    "torchrun",
    "--nproc_per_node=" + str(dist_cfg["nproc_per_node"]),
    str(SCRIPT_PATH),
]

env = os.environ.copy()
env.setdefault("TB_LOGDIR", str(LOG_DIR))

print("Running:\n", " ".join(cmd))
subprocess.run(cmd, check=True, env=env, cwd=str(LAUNCH_DIR))
```

è¿è¡Œç»“æœï¼š
```
Overwriting /root/zomi_moe/06AlgoData/02MoE/ep_launcher/launcher.py
Wrote launcher to /root/zomi_moe/06AlgoData/02MoE/ep_launcher/launcher.py
Running:
 torchrun --nproc_per_node=2 /root/zomi_moe/06AlgoData/02MoE/ep_launcher/launcher.py
[step 00000] task=0.3228 aux=0.7188 total=0.3300 interval_s=0.00
[step 01000] task=0.2033 aux=1.0053 total=0.2133 interval_s=11.74
[step 02000] task=0.1880 aux=0.8309 total=0.1963 interval_s=11.22
[step 03000] task=0.1810 aux=0.5976 total=0.1870 interval_s=11.20
[step 04000] task=0.1781 aux=0.5668 total=0.1838 interval_s=11.17
[step 05000] task=0.1801 aux=0.5431 total=0.1855 interval_s=11.02
[step 06000] task=0.1687 aux=0.5110 total=0.1738 interval_s=11.35
[step 07000] task=0.1789 aux=0.4121 total=0.1830 interval_s=11.16
[step 08000] task=0.1818 aux=0.4152 total=0.1859 interval_s=11.17
[step 09000] task=0.1774 aux=0.3601 total=0.1810 interval_s=11.28
EP MoE tiny training finished.
```

# æ€»ç»“

## æˆ‘ä»¬å®ç°äº†ä»€ä¹ˆï¼Ÿ

è¿™ä¸€ä»½å®ç°åˆ»æ„è¿½æ±‚â€œæœ€å°é—­ç¯ã€å¯è¯»å¯è·‘â€ï¼Œæ ¸å¿ƒè´¡çŒ®æ˜¯æŠŠ EP-MoE çš„æ•°æ®æµåœ¨ä»£ç é‡Œèµ°é€šï¼š

- **EP çš„æœ€å°å¯è¿è¡Œç‰ˆæœ¬**ï¼š
  - gateï¼ˆå¤åˆ¶åœ¨æ¯ä¸ª rankï¼‰è´Ÿè´£å¯¹ token åšè·¯ç”±æ‰“åˆ†ï¼›
  - expertsï¼ˆæŒ‰ rank åˆ†ç‰‡ï¼‰åªåœ¨æœ¬åœ°è®¡ç®—ï¼Œé¿å…æ¯å¼ å¡éƒ½æŒæœ‰å…¨é‡ä¸“å®¶ï¼›
  - dispatch/combine è´Ÿè´£è·¨ rank æ´¾å‘ token ä¸å›ä¼ ç»“æœã€‚
- **è‡ªå®šä¹‰çš„æ¨¡æ‹Ÿä»»åŠ¡**ï¼š
  - ç”¨ä¸€ä¸ªå›ºå®šçš„ `target_proj` ç”Ÿæˆç›‘ç£ä¿¡å·ï¼Œè®© MoE æ‹Ÿåˆçº¿æ€§æ˜ å°„ï¼›
  - è®­ç»ƒæŸå¤±ç”± `task_loss + aux_alpha * aux_loss` æ„æˆï¼š`task_loss` é©±åŠ¨ä»»åŠ¡æ‹Ÿåˆï¼Œ`aux_loss` çº¦æŸè·¯ç”±æ›´å‡è¡¡ï¼›
  - é€šè¿‡ `torchrun` å¯åŠ¨å¤šè¿›ç¨‹ï¼ŒéªŒè¯å¤šå¡ç¯å¢ƒä¸‹ forward/backward/optimizer step éƒ½èƒ½è·‘é€šã€‚
- **å¯è§£é‡Šçš„é€šä¿¡æ•°æ®ç»“æ„**ï¼š
  - å¯¹æ¯æ¡æ´¾å‘å‡ºå»çš„ token éƒ½è®°å½• `expert_meta`ï¼ˆå…¨å±€ä¸“å®¶ã€æº rankã€æº token ä¸‹æ ‡ã€topk åºå·ç­‰ï¼‰ï¼Œcombine æ—¶èƒ½ç²¾ç¡®å›å¡«ã€‚

## å½“å‰å®ç°çš„ä¸»è¦æ€§èƒ½ç“¶é¢ˆ

è¿™ä»½å®ç°æ˜¯â€œæ•™å­¦ç‰ˆâ€ï¼Œä¸ºäº†å¯è¯»æ€§ç‰ºç‰²äº†ä¸å°‘æ€§èƒ½ï¼Œä¸»è¦ç“¶é¢ˆé›†ä¸­åœ¨ä¸‰ç±»ï¼š

1. **Python å¾ªç¯ä¸æ•°æ®æ¬è¿ï¼ˆCPU ä¾§å¼€é”€ + kernel launch é¢‘ç¹ï¼‰**
   - dispatch æ—¶æŠŠ token å±•å¹³ã€é€æ¡ append/concatï¼›
   - è½æ¡¶æ—¶é€æ¡å†™å…¥ `expert_x/expert_meta`ï¼›
   - expert forward æ—¶é€ expert å¾ªç¯ï¼ˆæ¯æ¬¡è°ƒç”¨ä¸€ä¸ªå° MLPï¼‰ï¼Œåœ¨ä¸“å®¶å¤šã€token å¤šæ—¶ä¼šäº§ç”Ÿå¤§é‡å° kernel launchã€‚ã€æˆ‘å‘ç°[å¾ˆæ—©æœŸçš„Megatron_LM](https://zhuanlan.zhihu.com/p/666653126)ä¹Ÿæ˜¯è¿™ä¹ˆåšçš„ã€‘

2. **`all_gather + padding` çš„é€šä¿¡å½¢æ€ï¼ˆé¢å¤–æ‹·è´/å¸¦å®½æµªè´¹ï¼‰**
   - all_gather+pad æ–¹æ¡ˆï¼ˆå½“å‰ baselineï¼‰ï¼šä¸ºæ»¡è¶³å½¢çŠ¶ä¸€è‡´å…ˆ padï¼Œå†å…¨é‡æ”¶é›†ã€å† mask è¿‡æ»¤ï¼Œå¯¼è‡´å¤šæ¬¡æ‹·è´ï¼›è´Ÿè½½ä¸å‡æ—¶ pad è†¨èƒ€ï¼Œæœ‰æ•ˆè½½è·å æ¯”ä½ï¼Œé€šä¿¡å¸¦å®½æµªè´¹ã€‚
   - è¿™ç±»â€œå¹¿æ’­å¼æ”¶é›†â€æŠŠæ‰€æœ‰ rank çš„æ•°æ®éƒ½æ¬è¿‡æ¥ï¼Œæœ¬è´¨ä¸Šåšäº†å…¨é‡æ‰©æ•£ï¼Œé¢å¤–å¼€é”€é«˜ï¼›Megatron MoE çš„ MoETokenDispatcher-AlltoAll å°±æ˜¯è¿™ç§ baseline å½¢æ€ã€‚
   - ä¼˜åŒ–æ–¹å‘ï¼ˆå‚è€ƒ Megatron Flex/DeepEP æ€è·¯ï¼‰ï¼šç”¨çœŸæ­£çš„ all_to_all + split sizes/permuteï¼Œåªå‘ç»™ç›®æ ‡ rankï¼Œé¿å…å¤§è§„æ¨¡ pad å’Œå¹¿æ’­ï¼›åŒæ—¶é’ˆå¯¹å®½ EP å’Œâ€œæœºå†…é€šä¿¡å’Œè·¨æœºé€šä¿¡é€Ÿç‡å·®äº†ä¸€ä¸ªæ•°é‡çº§â€è¿™ä¸€åŸºæœ¬äº‹å®ï¼Œå»åšä¸¤é˜¶æ®µçš„è½¬å‘ï¼Œç”¨è·¨æœºé€šä¿¡+æœºå†…è½¬å‘çš„æ€è·¯å»å®é™…å‡å°‘è·¨æœºé€šä¿¡é‡ã€‚

3. **æœªå®ç° token capacity / drop ç­–ç•¥ï¼ˆçœŸå® MoE å¿…éœ€ï¼‰**
   - çœŸå® MoE æ¨ç†/è®­ç»ƒé‡Œé€šå¸¸éœ€è¦å¯¹æ¯ä¸ªä¸“å®¶è®¾å®š capacityï¼ˆæ¯ä¸ª expert æœ€å¤šå¤„ç†å¤šå°‘ tokenï¼‰ï¼Œå¦åˆ™æç«¯è·¯ç”±ä¼šå¯¼è‡´ OOM æˆ–ä¸¥é‡çš„å°¾å»¶è¿Ÿï¼›
   - å½“å‰å®ç°é‡Œç”¨ `max_recv = max_num_tokens * world_size` ä½œä¸ºç²—ä¸Šç•Œï¼Œè™½ç„¶â€œèƒ½è·‘â€ï¼Œä½†ï¼š
     - å†…å­˜å ç”¨åå¤§ï¼›
     - ä¸èƒ½è¡¨è¾¾â€œå®¹é‡ä¸è¶³æ—¶å¦‚ä½•å¤„ç†â€ï¼ˆdrop / reroute / overflow bufferï¼‰ï¼›
     - è´Ÿè½½æŠ–åŠ¨ä¼šæ›´æ˜æ˜¾ã€‚

## æœªæ¥ä¼˜åŒ–æ–¹å‘ï¼ˆä»æ˜“åˆ°éš¾ / ä»æ”¶ç›Šåˆ°å·¥ç¨‹é‡ï¼‰

ä¸‹é¢è¿™äº›ä¼˜åŒ–æ–¹å‘å¤§å¤šå¯¹åº”ä½ ä»£ç é‡Œå·²ç»æ ‡æ³¨çš„ TODO æˆ–è€…å½“å‰ç»“æ„è‡ªç„¶å»¶ä¼¸ï¼š

1. **ä¸“å®¶è®¡ç®—å‘é‡åŒ–ï¼šç”¨ `bmm`/batched GEMM æ›¿æ¢é€ä¸“å®¶å¾ªç¯**
   - ç›®æ ‡ï¼šæŠŠåŒä¸€å¼ å¡ä¸Šå¤šä¸ªæœ¬åœ°ä¸“å®¶çš„ MLP è®¡ç®—æ‰“åŒ…æˆæ›´å¤§çš„çŸ©é˜µä¹˜ï¼Œæé«˜ GPU åˆ©ç”¨ç‡ï¼›
   - å¸¸è§åšæ³•æ˜¯æŠŠè½æ¡¶åçš„ `expert_x` ç»„ç»‡æˆé€‚åˆ batch matmul çš„å¸ƒå±€ï¼Œå†ä¸€æ¬¡æ€§è·‘å®Œã€‚

2. **é€šä¿¡å½¢æ€ä¼˜åŒ–ï¼šä» `all_gather + mask` è¿ç§»åˆ° `all_to_all_single`ï¼ˆå¸¦ split sizesï¼‰**
   - ç›®æ ‡ï¼šåªæŠŠâ€œè¯¥å‘ç»™è°çš„â€å‘ç»™è°ï¼Œé¿å…å…¨é‡ gather å’Œå¤§é‡ paddingï¼›
   - å…³é”®å·¥ç¨‹ç‚¹ï¼š
     - éœ€è¦æ„å»ºæ¯ä¸ª rank çš„ `send_splits/recv_splits`ï¼›
     - combine ä¹Ÿåšé€†å‘ all-to-allï¼›
     - è¦ç¡®ä¿ autograd å‹å¥½ï¼ˆå¯ä»¥ç”¨ PyTorch åˆ†å¸ƒå¼çš„ autograd-aware ç®—å­æˆ–æ‰‹å†™ autograd Functionï¼‰ã€‚

3. **å®ç° capacity ä¸ overflow ç­–ç•¥ï¼ˆMoE å·¥ç¨‹åŒ–å¿…é¡»é¡¹ï¼‰**
   - æ¯ä¸ª expert è®¾å®šå®¹é‡ `capacity = ceil(tokens_per_rank * topk / num_experts * capacity_factor)`ï¼›
   - å½“æŸä¸ª expert è¶…è¿‡ capacityï¼š
     - æ¨ç†ï¼šå¸¸ç”¨ dropï¼Œå¯¹äºæº¢å‡ºtokenï¼Œèµ°æ®‹å·®é“¾æ¥ç›´æ¥è·³è¿‡ä¸“å®¶å±‚çš„è®¡ç®—ï¼›
     - è®­ç»ƒï¼šè¿™é‡Œä¸€èˆ¬ä¼šæœ‰load balance aux lossä½¿å¾—è®­ç»ƒæ—¶å€™ï¼Œå°½é‡è´Ÿè½½å‡è¡¡ï¼Œæ¯”å¦‚GShardã€SwitchTransformerï¼›DeepSeekv3ä¹Ÿæå‡ºäº†åŸºäºåŠ æ€§biasçš„non-aux-lossçš„load balanceè®­ç»ƒåŠæ³•ï¼Œåœ¨[DeepSeekv3 Tech Report](https://arxiv.org/pdf/2412.19437)çš„2.1.2ï¼ˆåŸç†ï¼‰å’Œ4.5.2ï¼ˆæ¶ˆèå®éªŒï¼‰ã€‚

![deepseek](./images/Practice03DistMoE04.png)

4. **æ¨ç†è·¯å¾„ä¸è®­ç»ƒè·¯å¾„åˆ†ç¦»**
   - è®­ç»ƒæ›´å…³æ³¨æ¢¯åº¦æ­£ç¡®ä¸æ•°å€¼ç¨³å®šï¼›
   - æ¨ç†æ›´å…³æ³¨å»¶è¿Ÿä¸ååï¼š
     - å¯ä»¥ç”¨æ›´æ¿€è¿›çš„ kernel èåˆã€æ›´ç´§å‡‘çš„ bufferï¼ˆæ¯”å¦‚æŒ‰ capacity å›ºå®šå¤§å°ï¼‰ã€æ›´å°‘çš„ dtype è½¬æ¢ï¼›
     - å¯èƒ½è¿˜ä¼šå¼•å…¥ expert cachingã€prefetchã€overlapï¼ˆé€šä¿¡/è®¡ç®—é‡å ï¼‰ç­‰ç­–ç•¥ã€‚

> è¿™é‡Œç®€å•è¯´ä¸€ä¸‹ï¼Œå‡å¦‚è¦åŠ  capacity è¿™ä¸ªåŠŸèƒ½çš„è¯ï¼Œå¤§æ¦‚æ¶‰åŠåˆ°å“ªäº›æ–‡ä»¶ï¼Œä»¥åŠå¦‚ä½•æ”¹åŠ¨ï¼š

* é…ç½®ï¼šåœ¨ MoEConfig åŠ  capacity_per_expertï¼ˆæˆ– capacity_factor æŒ‰å…¬å¼ç®—å®¹é‡ï¼‰ã€‚è®­ç»ƒå‰ç®—å¥½æ¯ä¸ª rank çš„ capacityã€‚
* è·¯ç”±/dispatch å‰æ‹¦æˆªï¼šåœ¨ EPMoE.forward é‡Œ top-k ä¹‹åã€è¿›å…¥ dispatch å‰åšå®¹é‡è£å‰ªã€‚ç»´æŠ¤ä¸€ä¸ª per_expert_counterï¼Œè¶…å‡º capacity çš„ token æ ‡è®°ä¸º droppedï¼š
  * å•å¡åˆ†æ”¯ï¼ˆworld_size==1ï¼‰é‡Œï¼Œè½æ¡¶ expert_inputs æ—¶è·³è¿‡è¶…é¢ tokenã€‚
  * å¤šå¡åˆ†æ”¯ï¼Œè°ƒç”¨ PyTorchAllToAll.dispatch æ—¶ä¼ å…¥å®¹é‡/ä½¿ç”¨ counterï¼ŒåªæŠŠæœªè¶…é¢çš„ token æ”¾è¿› send_tokens/send_metaã€‚
* PyTorchAllToAll.dispatchï¼ˆå¤šå¡è·¯å¾„ï¼‰ä¹Ÿè¦æ¥æ”¶ capacity æˆ– per_expert_counterï¼Œåœ¨æ„å»º send_tokens æ—¶è·³è¿‡è¶…é¢ï¼Œå¹¶åœ¨ expert_num_tokens é‡Œåªç»Ÿè®¡ä¿ç•™ä¸‹æ¥çš„ã€‚
* combine/residual å¤„ç†ï¼šå¯¹è¢«ä¸¢å¼ƒçš„ tokenï¼Œè¿”å›â€œæ®‹å·®â€å³å¯ï¼šå¯ä»¥æå‰åˆå§‹åŒ– out_tokens = xï¼ˆæˆ– x * 1.0ï¼‰æˆ–è€…å°†tokenå¯¹åº”çš„ä¸“å®¶æƒé‡ç½®0ï¼Œç„¶å combine å åŠ ä¸“å®¶è¾“å‡ºï¼›è¢« drop çš„ token æ²¡æœ‰ meta/weightï¼Œå°±ä¿æŒæ®‹å·®è¾“å‡ºï¼Œç›´æ¥è·³è¿‡ä¸“å®¶å±‚è®¡ç®—ã€‚
* æ¨å¯¼å®¹é‡ï¼š`capacity = ceil((tokens_per_rank * topk / num_experts) * capacity_factor)` å¸¸ç”¨ï¼Œé¿å…ç¡¬ç¼–ç ï¼›åœ¨è®­ç»ƒå…¥å£ç®—å‡ºå¹¶å†™å…¥ cfgã€‚
